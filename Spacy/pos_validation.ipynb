{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "501cb92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.vocab import Vocab\n",
    "from hazm import *\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1465e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "peykare = PeykareReader(root = '/repo/ebi/myPosTagger/resources/peykare/TextLabelData/', universal_pos=True)\n",
    "corpus_size = 344736"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bca8cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = islice(peykare.sents(), int(corpus_size*0.9) , corpus_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ad2bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34474it [24:43, 23.23it/s]                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.96      0.96      0.96     59195\n",
      "      ADJ,EZ       0.95      0.96      0.95     20435\n",
      "         ADP       1.00      1.00      1.00     97477\n",
      "      ADP,EZ       0.98      0.99      0.98      9551\n",
      "         ADV       0.96      0.96      0.96     14963\n",
      "      ADV,EZ       0.97      0.98      0.97       860\n",
      "       CCONJ       1.00      1.00      1.00     50441\n",
      "    CCONJ,EZ       0.99      0.99      0.99        97\n",
      "         DET       0.99      0.98      0.99     18708\n",
      "      DET,EZ       0.95      0.96      0.95      1973\n",
      "        INTJ       0.87      0.94      0.91        36\n",
      "        NOUN       0.98      0.98      0.98    182819\n",
      "     NOUN,EZ       0.98      0.98      0.98    160473\n",
      "         NUM       0.99      0.99      0.99     23916\n",
      "      NUM,EZ       0.92      0.95      0.93      1672\n",
      "        PRON       0.98      0.99      0.99     20160\n",
      "     PRON,EZ       0.94      0.96      0.95       230\n",
      "       PUNCT       1.00      1.00      1.00     79479\n",
      "       SCONJ       0.99      1.00      0.99     18472\n",
      "        VERB       1.00      1.00      1.00     72870\n",
      "\n",
      "    accuracy                           0.99    833827\n",
      "   macro avg       0.97      0.98      0.97    833827\n",
      "weighted avg       0.99      0.99      0.99    833827\n",
      "\n",
      "Precision                                   : 0.98569\n",
      "Recall                                      : 0.98567\n",
      "F1-Score                                    : 0.98568\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data, test_data = train_test_split(list(islice(peykare.sents(), corpus_size)), test_size=0.1, random_state=10)\n",
    "persian_nlp = spacy.load('/repo/ebi/myPosTagger/persian_spacy/gpu_uni_tranin90_randomstate10/model-best/')\n",
    "preds = []\n",
    "ys = []\n",
    "\n",
    "for sent in tqdm(test_data, total=int(corpus_size*0.1)):\n",
    "    doc = persian_nlp(' '.join([w for w, tag in sent]))\n",
    "    y = [tag for w, tag in sent]\n",
    "    pred = [w.tag_ for w in doc]\n",
    "    if len(y) == len(pred):\n",
    "        ys += y\n",
    "        preds += pred\n",
    "\n",
    "\n",
    "print(classification_report(ys, preds))\n",
    "\n",
    "print('Precision                                   : %.5f'%precision_score(ys, preds, average='weighted'))\n",
    "print('Recall                                      : %.5f'%recall_score(ys, preds, average='weighted'))\n",
    "print('F1-Score                                    : %.5f'%f1_score(ys, preds, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30c99072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 833827/833827 [00:00<00:00, 1894117.90it/s]\n"
     ]
    }
   ],
   "source": [
    "ys_not_EZ = []\n",
    "pred_not_EZ = []\n",
    "for i in tqdm(range(len(ys))):\n",
    "    ys_not_EZ.append(ys[i].split(',')[0])\n",
    "    pred_not_EZ.append(preds[i].split(',')[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "666e3406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.97      0.97      0.97     79630\n",
      "         ADP       1.00      1.00      1.00    107028\n",
      "         ADV       0.96      0.97      0.97     15823\n",
      "       CCONJ       1.00      1.00      1.00     50538\n",
      "         DET       0.98      0.98      0.98     20681\n",
      "        INTJ       0.87      0.94      0.91        36\n",
      "        NOUN       0.99      0.99      0.99    343292\n",
      "         NUM       1.00      1.00      1.00     25588\n",
      "        PRON       0.99      0.99      0.99     20390\n",
      "       PUNCT       1.00      1.00      1.00     79479\n",
      "       SCONJ       0.99      1.00      0.99     18472\n",
      "        VERB       1.00      1.00      1.00     72870\n",
      "\n",
      "    accuracy                           0.99    833827\n",
      "   macro avg       0.98      0.99      0.98    833827\n",
      "weighted avg       0.99      0.99      0.99    833827\n",
      "\n",
      "Precision                                   : 0.99252\n",
      "Recall                                      : 0.99252\n",
      "F1-Score                                    : 0.99252\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ys_not_EZ, pred_not_EZ))\n",
    "\n",
    "print('Precision                                   : %.5f'%precision_score(ys_not_EZ, pred_not_EZ, average='weighted'))\n",
    "print('Recall                                      : %.5f'%recall_score(ys_not_EZ, pred_not_EZ, average='weighted'))\n",
    "print('F1-Score                                    : %.5f'%f1_score(ys_not_EZ, pred_not_EZ, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239a41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8891fb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40b2db96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34474it [19:22, 29.65it/s]                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.93      0.95      0.94     15492\n",
      "        ADVe       0.95      0.96      0.96      1114\n",
      "          AJ       0.93      0.95      0.94     57804\n",
      "         AJe       0.91      0.90      0.90     14645\n",
      "          CL       0.80      0.86      0.83      1349\n",
      "        CONJ       1.00      1.00      1.00     74057\n",
      "       CONJe       1.00      0.91      0.95        74\n",
      "         DET       0.98      0.97      0.98     18171\n",
      "        DETe       0.90      0.93      0.92      2165\n",
      "         INT       0.96      0.87      0.92        31\n",
      "           N       0.97      0.95      0.96    152056\n",
      "         NUM       0.98      0.99      0.99     17963\n",
      "        NUMe       0.89      0.93      0.91      1690\n",
      "          Ne       0.97      0.97      0.97    119251\n",
      "           P       1.00      1.00      1.00     70916\n",
      "       POSTP       1.00      1.00      1.00     12911\n",
      "         PRO       0.98      0.98      0.98     23117\n",
      "        PROe       0.87      0.83      0.85       326\n",
      "        PUNC       1.00      1.00      1.00     82510\n",
      "          Pe       0.97      0.98      0.98      8590\n",
      "         RES       0.91      0.94      0.92      6803\n",
      "        RESe       0.78      0.17      0.27       168\n",
      "           V       1.00      0.99      1.00     75525\n",
      "\n",
      "    accuracy                           0.97    756728\n",
      "   macro avg       0.94      0.91      0.92    756728\n",
      "weighted avg       0.97      0.97      0.97    756728\n",
      "\n",
      "Precision                                   : 0.97479\n",
      "Recall                                      : 0.97468\n",
      "F1-Score                                    : 0.97466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "persian_nlp = spacy.load('output2/model-best/')\n",
    "test_data = islice(peykare.sents(), int(corpus_size*0.9) , corpus_size)\n",
    "preds = []\n",
    "ys = []\n",
    "\n",
    "for sent in tqdm(test_data, total=int(corpus_size*0.1)):\n",
    "    doc = persian_nlp(' '.join([w for w, tag in sent]))\n",
    "    y = [tag for w, tag in sent]\n",
    "    pred = [w.tag_ for w in doc]\n",
    "    if len(y) == len(pred):\n",
    "        ys += y\n",
    "        preds += pred\n",
    "\n",
    "\n",
    "print(classification_report(ys, preds))\n",
    "\n",
    "print('Precision                                   : %.5f'%precision_score(ys, preds, average='weighted'))\n",
    "print('Recall                                      : %.5f'%recall_score(ys, preds, average='weighted'))\n",
    "print('F1-Score                                    : %.5f'%f1_score(ys, preds, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b678ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdd787d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34474it [09:59, 57.52it/s]                                                                          \n",
      "/repo/ebi/myWord2vec/embed_venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/repo/ebi/myWord2vec/embed_venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/repo/ebi/myWord2vec/embed_venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.57      0.72      0.64     15485\n",
      "        ADVe       0.92      0.83      0.87      1114\n",
      "          AJ       0.68      0.62      0.65     57804\n",
      "         AJe       0.54      0.43      0.48     14645\n",
      "          CL       0.63      0.61      0.62      1349\n",
      "        CONJ       0.97      0.98      0.98     74055\n",
      "       CONJe       0.71      0.16      0.26        74\n",
      "         DET       0.92      0.93      0.92     18177\n",
      "        DETe       0.76      0.75      0.75      2165\n",
      "         INT       0.00      0.00      0.00        31\n",
      "           N       0.73      0.82      0.77    152056\n",
      "         NUM       0.85      0.93      0.89     17963\n",
      "        NUMe       0.30      0.04      0.07      1690\n",
      "          Ne       0.83      0.76      0.79    119251\n",
      "           P       0.98      1.00      0.99     70919\n",
      "       POSTP       1.00      1.00      1.00     12911\n",
      "         PRO       0.90      0.92      0.91     23117\n",
      "        PROe       0.42      0.56      0.48       326\n",
      "        PUNC       1.00      0.97      0.98     82510\n",
      "          Pe       0.90      0.90      0.90      8590\n",
      "         RES       0.47      0.08      0.14      6803\n",
      "        RESe       0.00      0.00      0.00       168\n",
      "           V       0.94      0.96      0.95     75525\n",
      "\n",
      "    accuracy                           0.85    756728\n",
      "   macro avg       0.70      0.65      0.65    756728\n",
      "weighted avg       0.85      0.85      0.85    756728\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/repo/ebi/myWord2vec/embed_venv/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision                                   : 0.848\n",
      "Recall                                      : 0.851\n",
      "F1-Score                                    : 0.847\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "persian_nlp = spacy.load('output/model-best/')\n",
    "test_data = islice(peykare.sents(), int(corpus_size*0.9) , corpus_size)\n",
    "preds = []\n",
    "ys = []\n",
    "\n",
    "for sent in tqdm(test_data, total=int(corpus_size*0.1)):\n",
    "    doc = persian_nlp(' '.join([w for w, tag in sent]))\n",
    "    y = [tag for w, tag in sent]\n",
    "    pred = [w.tag_ for w in doc]\n",
    "    if len(y) == len(pred):\n",
    "        ys += y\n",
    "        preds += pred\n",
    "\n",
    "\n",
    "print(classification_report(ys, preds))\n",
    "\n",
    "print('Precision                                   : %.5f'%precision_score(ys, preds, average='weighted'))\n",
    "print('Recall                                      : %.5f'%recall_score(ys, preds, average='weighted'))\n",
    "print('F1-Score                                    : %.5f'%f1_score(ys, preds, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220e4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edb1101f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 2728599552 bytes == 0x3a464000 @ \n",
      "34474it [09:01, 63.67it/s]                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.94      0.94      0.94     15492\n",
      "        ADVe       0.99      0.93      0.96      1114\n",
      "          AJ       0.95      0.94      0.95     57804\n",
      "         AJe       0.89      0.93      0.91     14645\n",
      "          CL       0.84      0.80      0.82      1349\n",
      "        CONJ       0.99      1.00      0.99     74057\n",
      "       CONJe       1.00      1.00      1.00        74\n",
      "         DET       0.97      0.97      0.97     18171\n",
      "        DETe       0.92      0.94      0.93      2165\n",
      "         INT       0.85      0.94      0.89        31\n",
      "           N       0.97      0.96      0.96    152056\n",
      "         NUM       0.99      0.98      0.98     17963\n",
      "        NUMe       0.88      0.94      0.91      1690\n",
      "          Ne       0.96      0.97      0.97    119251\n",
      "           P       1.00      1.00      1.00     70916\n",
      "       POSTP       1.00      1.00      1.00     12911\n",
      "         PRO       0.98      0.97      0.97     23117\n",
      "        PROe       0.85      0.76      0.80       326\n",
      "        PUNC       1.00      1.00      1.00     82510\n",
      "          Pe       0.97      0.99      0.98      8590\n",
      "         RES       0.94      0.94      0.94      6803\n",
      "        RESe       0.63      0.69      0.66       168\n",
      "           V       1.00      1.00      1.00     75525\n",
      "\n",
      "    accuracy                           0.98    756728\n",
      "   macro avg       0.94      0.94      0.94    756728\n",
      "weighted avg       0.98      0.98      0.98    756728\n",
      "\n",
      "Precision                                   : 0.97532\n",
      "Recall                                      : 0.97526\n",
      "F1-Score                                    : 0.97527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "persian_nlp = spacy.load('tune1_train95_test5/model-best/')\n",
    "test_data = islice(peykare.sents(), int(corpus_size*0.9) , corpus_size)\n",
    "preds = []\n",
    "ys = []\n",
    "\n",
    "for sent in tqdm(test_data, total=int(corpus_size*0.1)):\n",
    "    doc = persian_nlp(' '.join([w for w, tag in sent]))\n",
    "    y = [tag for w, tag in sent]\n",
    "    pred = [w.tag_ for w in doc]\n",
    "    if len(y) == len(pred):\n",
    "        ys += y\n",
    "        preds += pred\n",
    "\n",
    "\n",
    "print(classification_report(ys, preds))\n",
    "\n",
    "print('Precision                                   : %.5f'%precision_score(ys, preds, average='weighted'))\n",
    "print('Recall                                      : %.5f'%recall_score(ys, preds, average='weighted'))\n",
    "print('F1-Score                                    : %.5f'%f1_score(ys, preds, average='weighted'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3b0ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4817e4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 2728599552 bytes == 0x3a4a6000 @ \n",
      "34474it [10:02, 57.17it/s]                                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.96      0.91      0.93     15492\n",
      "        ADVe       0.99      0.94      0.96      1114\n",
      "          AJ       0.94      0.94      0.94     57804\n",
      "         AJe       0.90      0.90      0.90     14645\n",
      "          CL       0.85      0.83      0.84      1349\n",
      "        CONJ       0.99      1.00      0.99     74057\n",
      "       CONJe       0.99      1.00      0.99        74\n",
      "         DET       0.98      0.97      0.97     18171\n",
      "        DETe       0.94      0.93      0.93      2165\n",
      "         INT       0.93      0.87      0.90        31\n",
      "           N       0.96      0.96      0.96    152056\n",
      "         NUM       0.98      0.99      0.98     17963\n",
      "        NUMe       0.87      0.90      0.89      1690\n",
      "          Ne       0.96      0.97      0.97    119251\n",
      "           P       1.00      1.00      1.00     70916\n",
      "       POSTP       1.00      1.00      1.00     12911\n",
      "         PRO       0.98      0.97      0.98     23117\n",
      "        PROe       0.72      0.90      0.80       326\n",
      "        PUNC       1.00      1.00      1.00     82510\n",
      "          Pe       0.96      0.99      0.97      8590\n",
      "         RES       0.93      0.90      0.91      6803\n",
      "        RESe       0.63      0.47      0.54       168\n",
      "           V       1.00      1.00      1.00     75525\n",
      "\n",
      "    accuracy                           0.97    756728\n",
      "   macro avg       0.93      0.93      0.93    756728\n",
      "weighted avg       0.97      0.97      0.97    756728\n",
      "\n",
      "Precision                                   : 0.973\n",
      "Recall                                      : 0.973\n",
      "F1-Score                                    : 0.973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "persian_nlp = spacy.load('outputLast/model-best/')\n",
    "test_data = islice(peykare.sents(), int(corpus_size*0.9) , corpus_size)\n",
    "preds = []\n",
    "ys = []\n",
    "\n",
    "for sent in tqdm(test_data, total=int(corpus_size*0.1)):\n",
    "    doc = persian_nlp(' '.join([w for w, tag in sent]))\n",
    "    y = [tag for w, tag in sent]\n",
    "    pred = [w.tag_ for w in doc]\n",
    "    if len(y) == len(pred):\n",
    "        ys += y\n",
    "        preds += pred\n",
    "\n",
    "\n",
    "print(classification_report(ys, preds))\n",
    "\n",
    "print('Precision                                   : %.5f'%precision_score(ys, preds, average='weighted'))\n",
    "print('Recall                                      : %.5f'%recall_score(ys, preds, average='weighted'))\n",
    "print('F1-Score                                    : %.5f'%f1_score(ys, preds, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cfb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93f86902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34474it [09:24, 61.03it/s]                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.94      0.92      0.93     15492\n",
      "        ADVe       0.97      0.96      0.96      1114\n",
      "          AJ       0.94      0.93      0.93     57804\n",
      "         AJe       0.89      0.88      0.89     14645\n",
      "          CL       0.81      0.82      0.82      1349\n",
      "        CONJ       0.99      1.00      1.00     74057\n",
      "       CONJe       1.00      1.00      1.00        74\n",
      "         DET       0.98      0.97      0.97     18171\n",
      "        DETe       0.91      0.94      0.93      2165\n",
      "         INT       0.83      0.94      0.88        31\n",
      "           N       0.95      0.95      0.95    152056\n",
      "         NUM       0.98      0.99      0.98     17963\n",
      "        NUMe       0.86      0.92      0.89      1690\n",
      "          Ne       0.96      0.96      0.96    119251\n",
      "           P       1.00      1.00      1.00     70916\n",
      "       POSTP       1.00      1.00      1.00     12911\n",
      "         PRO       0.97      0.99      0.98     23117\n",
      "        PROe       0.87      0.50      0.63       326\n",
      "        PUNC       1.00      1.00      1.00     82510\n",
      "          Pe       0.97      0.98      0.98      8590\n",
      "         RES       0.92      0.87      0.89      6803\n",
      "        RESe       0.63      0.25      0.36       168\n",
      "           V       0.99      0.99      0.99     75525\n",
      "\n",
      "    accuracy                           0.97    756728\n",
      "   macro avg       0.93      0.90      0.91    756728\n",
      "weighted avg       0.97      0.97      0.97    756728\n",
      "\n",
      "Precision                                   : 0.97004\n",
      "Recall                                      : 0.97014\n",
      "F1-Score                                    : 0.97003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "persian_nlp = spacy.load('../persian_spacy2/testOutput/model-best/')\n",
    "test_data = islice(peykare.sents(), int(corpus_size*0.9) , corpus_size)\n",
    "preds = []\n",
    "ys = []\n",
    "\n",
    "for sent in tqdm(test_data, total=int(corpus_size*0.1)):\n",
    "    doc = persian_nlp(' '.join([w for w, tag in sent]))\n",
    "    y = [tag for w, tag in sent]\n",
    "    pred = [w.tag_ for w in doc]\n",
    "    if len(y) == len(pred):\n",
    "        ys += y\n",
    "        preds += pred\n",
    "\n",
    "\n",
    "print(classification_report(ys, preds))\n",
    "\n",
    "print('Precision                                   : %.5f'%precision_score(ys, preds, average='weighted'))\n",
    "print('Recall                                      : %.5f'%recall_score(ys, preds, average='weighted'))\n",
    "print('F1-Score                                    : %.5f'%f1_score(ys, preds, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63b8c64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/repo/ebi/myPosTagger/persian_spacy\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49b1751f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 2728599552 bytes == 0x3b90c000 @ \n",
      "34474it [31:07, 18.46it/s]                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.95      0.96      0.95     15492\n",
      "        ADVe       0.99      0.95      0.97      1114\n",
      "          AJ       0.96      0.96      0.96     57804\n",
      "         AJe       0.93      0.93      0.93     14645\n",
      "          CL       0.85      0.86      0.85      1349\n",
      "        CONJ       0.99      1.00      1.00     74057\n",
      "       CONJe       1.00      1.00      1.00        74\n",
      "         DET       0.99      0.98      0.98     18172\n",
      "        DETe       0.92      0.95      0.93      2165\n",
      "         INT       0.93      0.90      0.92        31\n",
      "           N       0.97      0.97      0.97    152083\n",
      "         NUM       0.98      0.99      0.99     17963\n",
      "        NUMe       0.89      0.94      0.92      1690\n",
      "          Ne       0.97      0.98      0.98    119267\n",
      "           P       1.00      1.00      1.00     70879\n",
      "       POSTP       1.00      1.00      1.00     12911\n",
      "         PRO       0.98      0.98      0.98     23126\n",
      "        PROe       0.89      0.94      0.92       326\n",
      "        PUNC       1.00      1.00      1.00     82510\n",
      "          Pe       0.97      0.99      0.98      8574\n",
      "         RES       0.92      0.95      0.94      6803\n",
      "        RESe       0.65      0.60      0.63       168\n",
      "           V       1.00      1.00      1.00     75525\n",
      "\n",
      "    accuracy                           0.98    756728\n",
      "   macro avg       0.95      0.95      0.95    756728\n",
      "weighted avg       0.98      0.98      0.98    756728\n",
      "\n",
      "Precision                                   : 0.981\n",
      "Recall                                      : 0.981\n",
      "F1-Score                                    : 0.981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "persian_nlp = spacy.load('tune2_gpu_default/model-best/')\n",
    "test_data = islice(peykare.sents(), int(corpus_size*0.9) , corpus_size)\n",
    "preds = []\n",
    "ys = []\n",
    "not_match = 0\n",
    "\n",
    "for sent in tqdm(test_data, total=int(corpus_size*0.1)):\n",
    "    doc = persian_nlp(' '.join([w for w, tag in sent]))\n",
    "    y = [tag for w, tag in sent]\n",
    "    pred = [w.tag_ for w in doc]\n",
    "    if len(y) == len(pred):\n",
    "        ys += y\n",
    "        preds += pred\n",
    "    else:\n",
    "        not_match += 1\n",
    "        \n",
    "\n",
    "\n",
    "print(classification_report(ys, preds))\n",
    "\n",
    "print('Precision                                   : %.3f'%precision_score(ys, preds, average='weighted'))\n",
    "print('Recall                                      : %.3f'%recall_score(ys, preds, average='weighted'))\n",
    "print('F1-Score                                    : %.3f'%f1_score(ys, preds, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccbbab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADV       0.94      0.96      0.95     15485\n",
      "        ADVe       0.99      0.95      0.97      1114\n",
      "          AJ       0.96      0.96      0.96     57804\n",
      "         AJe       0.93      0.93      0.93     14645\n",
      "          CL       0.85      0.86      0.85      1349\n",
      "        CONJ       0.99      1.00      1.00     74057\n",
      "       CONJe       1.00      1.00      1.00        74\n",
      "         DET       0.99      0.98      0.98     18177\n",
      "        DETe       0.92      0.95      0.93      2165\n",
      "         INT       0.93      0.90      0.92        31\n",
      "           N       0.97      0.97      0.97    152056\n",
      "         NUM       0.98      0.99      0.99     17964\n",
      "        NUMe       0.89      0.94      0.92      1690\n",
      "          Ne       0.97      0.98      0.98    119251\n",
      "           P       1.00      1.00      1.00     70907\n",
      "       POSTP       1.00      1.00      1.00     12911\n",
      "         PRO       0.98      0.98      0.98     23126\n",
      "        PROe       0.89      0.94      0.92       326\n",
      "        PUNC       1.00      1.00      1.00     82510\n",
      "          Pe       0.98      0.99      0.98      8590\n",
      "         RES       0.92      0.95      0.94      6803\n",
      "        RESe       0.65      0.60      0.63       168\n",
      "           V       1.00      1.00      1.00     75525\n",
      "\n",
      "    accuracy                           0.98    756728\n",
      "   macro avg       0.95      0.95      0.95    756728\n",
      "weighted avg       0.98      0.98      0.98    756728\n",
      "\n",
      "Precision                                   : 0.981\n",
      "Recall                                      : 0.981\n",
      "F1-Score                                    : 0.981\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ys, preds))\n",
    "\n",
    "print('Precision                                   : %.3f'%precision_score(ys, preds, average='weighted'))\n",
    "print('Recall                                      : %.3f'%recall_score(ys, preds, average='weighted'))\n",
    "print('F1-Score                                    : %.3f'%f1_score(ys, preds, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9296988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4162\n"
     ]
    }
   ],
   "source": [
    "print(not_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce141c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3b6737",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc5123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a0be1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24175bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "\"\"\"این ماژول شامل کلاس‌ها و توابعی برای خواندن پیکرهٔ Peykare است. \n",
    "[peykare پیکرهٔ](https://www.peykaregan.ir/dataset/%D9%BE%DB%8C%DA%A9%D8%B1%D9%87-%D9%85%D8%AA%D9%86%DB%8C-%D8%B2%D8%A8%D8%A7%D9%86-%D9%81%D8%A7%D8%B1%D8%B3%DB%8C)\n",
    "جموعه‌ای از متون نوشتاری و گفتاری رسمی زبان فارسی است که از منابع واقعی همچون\n",
    "روزنامه‌ها، سایت‌ها و مستنداتِ از قبل تایپ‌شده، جمع‌آوری شده، تصحیح گردیده و\n",
    "برچسب خورده است. حجم این دادگان حدوداً ۱۰۰ میلیون کلمه است و از منابع مختلف تهیه\n",
    "گردیده و دارای تنوع بسیار زیادی است. ۱۰ میلیون کلمه از این پیکره با استفاده از\n",
    "۸۸۲ برچسب نحوی-معنایی به صورت دستی توسط دانشجویان رشتهٔ زبان‌شناسی برچسب‌دهی\n",
    "شده‌اند و هر پرونده بر حسب موضوع و منبع آن طبقه‌بندی شده است. این پیکره که توسط\n",
    "پژوهشکده پردازش هوشمند علائم تهیه شده است، برای استفاده در آموزش مدل زبانی و\n",
    "سایر پروژه‌های مربوط به پردازش زبان طبیعی مناسب است.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "import os, codecs\n",
    "from hazm import Normalizer\n",
    "from hazm import WordTokenizer\n",
    "\n",
    "\n",
    "def coarse_pos_u(tags, word):\n",
    "    \"\"\"برچسب‌های ریز را به برچسب‌های درشت منطبق با استاندارد جهانی (coarse-grained universal pos tags) تبدیل می‌کند.\n",
    "    Examples:\n",
    "            >>> coarse_pos_u(['N','COM','SING'], 'الجزیره')\n",
    "            'NOUN'\n",
    "    Args:\n",
    "            tags (List[str]): لیست برچسب‌های ریز.\n",
    "    Returns:\n",
    "            (List[str]): لیست برچسب‌های درشت جهانی.\n",
    "    \"\"\"\n",
    "\n",
    "    map_pos_to_upos = {\n",
    "        \"N\": \"NOUN\",\n",
    "        \"V\": \"VERB\",\n",
    "        \"AJ\": \"ADJ\",\n",
    "        \"ADV\": \"ADV\",\n",
    "        \"PRO\": \"PRON\",\n",
    "        \"DET\": \"DET\",\n",
    "        \"P\": \"ADP\",\n",
    "        \"POSTP\": \"ADP\",\n",
    "        \"NUM\": \"NUM\",\n",
    "        \"CONJ\": \"CCONJ\",\n",
    "        \"PUNC\": \"PUNCT\",\n",
    "        \"CL\": \"NOUN\",\n",
    "        \"INT\": \"INTJ\",\n",
    "        \"RES\": \"NOUN\",\n",
    "    }\n",
    "    sconj_list = {\n",
    "        \"که\",\n",
    "        \"تا\",\n",
    "        \"گرچه\",\n",
    "        \"اگرچه\",\n",
    "        \"چرا\",\n",
    "        \"زیرا\",\n",
    "        \"اگر\",\n",
    "        \"چون\",\n",
    "        \"چراکه\",\n",
    "        \"هرچند\",\n",
    "        \"وگرنه\",\n",
    "        \"چنانچه\",\n",
    "        \"والا\",\n",
    "        \"هرچه\",\n",
    "        \"ولو\",\n",
    "        \"مگر\",\n",
    "        \"پس\",\n",
    "        \"چو\",\n",
    "        \"چه\",\n",
    "        \"بنابراین\",\n",
    "        \"وقتی\",\n",
    "        \"والّا\",\n",
    "        \"انگاری\",\n",
    "        \"هرچندكه\",\n",
    "        \"درنتيجه\",\n",
    "        \"اگه\",\n",
    "        \"ازآنجاكه\",\n",
    "        \"گر\",\n",
    "        \"وگر\",\n",
    "        \"وقتيكه\",\n",
    "        \"تااينكه\",\n",
    "        \"زمانيكه\",\n",
    "    }\n",
    "    num_adj_list = {\n",
    "        \"نخست\",\n",
    "        \"دوم\",\n",
    "        \"اول\",\n",
    "        \"پنجم\",\n",
    "        \"آخر\",\n",
    "        \"يازدهم\",\n",
    "        \"نهم\",\n",
    "        \"چهارم\",\n",
    "        \"ششم\",\n",
    "        \"پانزدهم\",\n",
    "        \"دوازدهم\",\n",
    "        \"هشتم\",\n",
    "        \"صدم\",\n",
    "        \"هفتم\",\n",
    "        \"هفدهم\",\n",
    "        \"آخرين\",\n",
    "        \"سيزدهم\",\n",
    "        \"يكم\",\n",
    "        \"بيستم\",\n",
    "        \"ويكم\",\n",
    "        \"دوسوم\",\n",
    "        \"شانزدهم\",\n",
    "        \"هجدهم\",\n",
    "        \"چهاردهم\",\n",
    "        \"ششصدم\",\n",
    "        \"ميليونيم\",\n",
    "        \"وهفتم\",\n",
    "        \"يازدهمين\",\n",
    "        \"هيجدهمين\",\n",
    "        \"واپسين\",\n",
    "        \"چهلم\",\n",
    "        \"هزارم\",\n",
    "        \"وپنجم\",\n",
    "        \"هيجدهم\",\n",
    "        \"ميلياردم\",\n",
    "        \"ميليونيوم\",\n",
    "        \"تريليونيوم\",\n",
    "        \"چهارپنجم\",\n",
    "        \"دهگانه\",\n",
    "        \"ميليونم\",\n",
    "        \"اوّل\",\n",
    "        \"سوّم\",\n",
    "    }\n",
    "    try:\n",
    "        old_pos = list(\n",
    "            set(tags)\n",
    "            & {\n",
    "                \"N\",\n",
    "                \"V\",\n",
    "                \"AJ\",\n",
    "                \"ADV\",\n",
    "                \"PRO\",\n",
    "                \"DET\",\n",
    "                \"P\",\n",
    "                \"POSTP\",\n",
    "                \"NUM\",\n",
    "                \"CONJ\",\n",
    "                \"PUNC\",\n",
    "                \"CL\",\n",
    "                \"INT\",\n",
    "                \"RES\",\n",
    "            }\n",
    "        )[0] \n",
    "        if old_pos == \"CONJ\" and word in sconj_list:\n",
    "            return \"SCONJ\"\n",
    "        if old_pos == \"NUM\" and word in num_adj_list:\n",
    "            return \"ADJ\" + (\",EZ\" if \"EZ\" in tags else \"\")\n",
    "        return map_pos_to_upos[old_pos] + (\",EZ\" if \"EZ\" in tags else \"\")\n",
    "    except:\n",
    "        return \"NOUN\"\n",
    "\n",
    "\n",
    "def coarse_pos_e(tags, word):\n",
    "    \"\"\"برچسب‌های ریز را به برچسب‌های درشت (coarse-grained pos tags) تبدیل می‌کند.\n",
    "    Examples:\n",
    "            >>> coarse_pos_e(['N','COM','SING'], 'الجزیره')\n",
    "            'N'\n",
    "    Args:\n",
    "            tags (List[str]): لیست برچسب‌های ریز.\n",
    "    Returns:\n",
    "            (List[str]): لیست برچسب‌های درشت.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        return list(\n",
    "            set(tags)\n",
    "            & {\n",
    "                \"N\",\n",
    "                \"V\",\n",
    "                \"AJ\",\n",
    "                \"ADV\",\n",
    "                \"PRO\",\n",
    "                \"DET\",\n",
    "                \"P\",\n",
    "                \"POSTP\",\n",
    "                \"NUM\",\n",
    "                \"CONJ\",\n",
    "                \"PUNC\",\n",
    "                \"CL\",\n",
    "                \"INT\",\n",
    "                \"RES\",\n",
    "            }\n",
    "        )[0] + (\",EZ\" if \"EZ\" in tags else \"\")\n",
    "    except:\n",
    "        return \"N\"\n",
    "\n",
    "\n",
    "def join_verb_parts(sentence):\n",
    "    \"\"\"جمله را در قالب لیستی از `(توکن، برچسب)‌`ها می‌گیرد و توکن‌های مربوط به افعال چندبخشی را با کاراکتر زیرخط (_) به هم می‌چسباند.\n",
    "    Examples:\n",
    "            >>> join_verb_parts([('اولین', 'AJ'), ('سیاره', 'Ne'), ('خارج', 'AJ'), ('از', 'P'), ('منظومه', 'Ne'), ('شمسی', 'AJ'), ('دیده', 'AJ'), ('شد', 'V'), ('.', 'PUNC')])\n",
    "            [('اولین', 'AJ'), ('سیاره', 'Ne'), ('خارج', 'AJ'), ('از', 'P'), ('منظومه', 'Ne'), ('شمسی', 'AJ'), ('دیده_شد', 'V'), ('.', 'PUNC')]\n",
    "    Args:\n",
    "            sentence(List[Tuple[str,str]]): جمله در قالب لیستی از `(توکن، برچسب)`ها.\n",
    "    Returns:\n",
    "            (List[Tuple[str, str]): لیستی از `(توکن، برچسب)`ها که در آن افعال چندبخشی در قالب یک توکن با کاراکتر زیرخط به هم چسبانده شده‌اند.\n",
    "    \"\"\"\n",
    "\n",
    "    if not hasattr(join_verb_parts, \"tokenizer\"):\n",
    "        join_verb_parts.tokenizer = WordTokenizer()\n",
    "    before_verbs, after_verbs, verbe = (\n",
    "        join_verb_parts.tokenizer.before_verbs,\n",
    "        join_verb_parts.tokenizer.after_verbs,\n",
    "        join_verb_parts.tokenizer.verbe,\n",
    "    )\n",
    "\n",
    "    result = [(\"\", \"\")]\n",
    "    for word in reversed(sentence):\n",
    "        if word[0] in before_verbs or (\n",
    "            result[-1][0] in after_verbs and word[0] in verbe\n",
    "        ):\n",
    "            result[-1] = (word[0] + \"_\" + result[-1][0], result[-1][1])\n",
    "        else:\n",
    "            result.append(word)\n",
    "    return list(reversed(result[1:]))\n",
    "\n",
    "\n",
    "class PeykareReader:\n",
    "    \"\"\"این کلاس شامل توابعی برای خواندن پیکرهٔ Peykare است.\n",
    "    Args:\n",
    "            root (str): آدرس فولدر حاوی فایل‌های پیکره.\n",
    "            join_verb_parts (bool, optional): اگر `True‍` باشد افعال چندقسمتی به‌شکل چسبیده‌به‌هم برگردانده_می‌شود.\n",
    "            pos_map (str): دیکشنری مبدل برچسب‌های ریز به درشت.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, root, joined_verb_parts=True, pos_map=coarse_pos_e, universal_pos=False\n",
    "    ):\n",
    "        self._root = root\n",
    "        if pos_map is None:\n",
    "            self._pos_map = lambda tags: \",\".join(tags)\n",
    "        elif universal_pos:\n",
    "            self._pos_map = coarse_pos_u\n",
    "        else:\n",
    "            self._pos_map = coarse_pos_e\n",
    "        self._joined_verb_parts = joined_verb_parts\n",
    "        self._normalizer = Normalizer(punctuation_spacing=False, affix_spacing=False)\n",
    "\n",
    "    def docs(self):\n",
    "        \"\"\"اسناد را به شکل متن خام برمی‌گرداند.\n",
    "        Yields:\n",
    "                (str): متن خام سند بعدی.\n",
    "        \"\"\"\n",
    "\n",
    "        for root, dirs, files in os.walk(self._root):\n",
    "            for name in sorted(files):\n",
    "                with codecs.open(\n",
    "                    os.path.join(root, name), encoding=\"windows-1256\"\n",
    "                ) as peykare_file:\n",
    "                    text = peykare_file.read()\n",
    "                    if text:\n",
    "                        yield text\n",
    "\n",
    "    def doc_to_sents(self, document):\n",
    "        \"\"\"سند ورودی را به لیستی از جملات تبدیل می‌کند.\n",
    "        هر جمله لیستی از `(کلمه, برچسب)`ها است.\n",
    "        Args:\n",
    "                document (str): سندی که باید تبدیل شود.\n",
    "        Yields:\n",
    "                (List[(str,str)]): `ها جملهٔ بعدی در قالب لیستی از `(کلمه، برچسب).\n",
    "        \"\"\"\n",
    "\n",
    "        sentence = []\n",
    "        for line in document.split(\"\\r\\n\"):\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            parts = line.split(\" \")\n",
    "            tags, word = parts[3], self._normalizer.normalize(\"‌\".join(parts[4:]))\n",
    "\n",
    "            if word and word != \"#\":\n",
    "                sentence.append((word, tags))\n",
    "\n",
    "            if parts[2] == \"PUNC\" and word in {\"#\", \".\", \"؟\", \"!\"}:\n",
    "                if len(sentence) > 1:\n",
    "                    yield sentence\n",
    "                sentence = []\n",
    "\n",
    "    def sents(self):\n",
    "        \"\"\"جملات پیکره را در قالب لیستی از `(توکن، برچسب)`ها برمی‌گرداند.\n",
    "        Examples:\n",
    "                >>> peykare = PeykareReader(root='corpora/peykare')\n",
    "                >>> next(peykare.sents())\n",
    "                [('دیرزمانی', 'N'), ('از', 'P'), ('راه‌اندازی', 'Ne'), ('شبکه‌ی', 'Ne'), ('خبر', 'Ne'), ('الجزیره', 'N'), ('نمی‌گذرد', 'V'), ('،', 'PUNC'), ('اما', 'CONJ'), ('این', 'DET'), ('شبکه‌ی', 'Ne'), ('خبری', 'AJe'), ('عربی', 'N'), ('بسیار', 'ADV'), ('سریع', 'ADV'), ('توانسته', 'V'), ('در', 'P'), ('میان', 'Ne'), ('شبکه‌های', 'Ne'), ('عظیم', 'AJe'), ('خبری', 'AJ'), ('و', 'CONJ'), ('بنگاه‌های', 'Ne'), ('چندرسانه‌ای', 'AJe'), ('دنیا', 'N'), ('خودی', 'N'), ('نشان', 'N'), ('دهد', 'V'), ('.', 'PUNC')]\n",
    "                >>> peykare = PeykareReader(root='corpora/peykare', joined_verb_parts=False, pos_map=None)\n",
    "                >>> next(peykare.sents())\n",
    "                [('دیرزمانی', 'N,COM,SING,TIME,YA'), ('از', 'P'), ('راه‌اندازی', 'N,COM,SING,EZ'), ('شبکه‌ی', 'N,COM,SING,EZ'), ('خبر', 'N,COM,SING,EZ'), ('الجزیره', 'N,PR,SING'), ('نمی‌گذرد', 'V,PRES,NEG,3'), ('،', 'PUNC'), ('اما', 'CONJ'), ('این', 'DET,DEMO'), ('شبکه‌ی', 'N,COM,SING,EZ'), ('خبری', 'AJ,SIM,EZ'), ('عربی', 'N,PR,SING'), ('بسیار', 'ADV,INTSF,SIM'), ('سریع', 'ADV,GENR,SIM'), ('توانسته', 'V,PASTP'), ('در', 'P'), ('میان', 'N,COM,SING,EZ'), ('شبکه‌های', 'N,COM,PL,EZ'), ('عظیم', 'AJ,SIM,EZ'), ('خبری', 'AJ,SIM'), ('و', 'CONJ'), ('بنگاه‌های', 'N,COM,PL,EZ'), ('چندرسانه‌ای', 'AJ,SIM,EZ'), ('دنیا', 'N,COM,SING'), ('خودی', 'N,COM,SING,YA'), ('نشان', 'N,COM,SING'), ('دهد', 'V,SUB,POS,3'), ('.', 'PUNC')]\n",
    "        Yields:\n",
    "                (List[Tuple[str,str]]): جملهٔ بعدی در قالب لیستی از `(توکن، برچسب)`ها.\n",
    "        \"\"\"\n",
    "        map_pos = lambda item: (item[0], self._pos_map(item[1].split(\",\"), item[0]))\n",
    "\n",
    "        for document in self.docs():\n",
    "            for sentence in self.doc_to_sents(document):\n",
    "                if self._joined_verb_parts:\n",
    "                    sentence = join_verb_parts(sentence)\n",
    "                yield list(map(map_pos, sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9e86b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1778549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867bd401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8938497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(list(islice(peykare.sents(), corpus_size)), test_size=0.1, random_state=10)\n",
    "persian_nlp = spacy.load('/repo/ebi/myPosTagger/persian_spacy/gpu_uni_tranin90_randomstate10/model-best/')\n",
    "preds = []\n",
    "ys = []\n",
    "not_match = 0\n",
    "\n",
    "for sent in tqdm(test_data, total=int(corpus_size*0.1)):\n",
    "    doc = persian_nlp(' '.join([w for w, tag in sent]))\n",
    "    y = [tag for w, tag in sent]\n",
    "    pred = [w.tag_ for w in doc]\n",
    "    if len(y) == len(pred):\n",
    "        ys += y\n",
    "        preds += pred\n",
    "    else:\n",
    "        not_match +=1\n",
    "\n",
    "\n",
    "print(classification_report(ys, preds))\n",
    "\n",
    "print('Precision                                   : %.5f'%precision_score(ys, preds, average='weighted'))\n",
    "print('Recall                                      : %.5f'%recall_score(ys, preds, average='weighted'))\n",
    "print('F1-Score                                    : %.5f'%f1_score(ys, preds, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1f9108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "persian_nlp = spacy.load('/repo/ebi/myPosTagger/persian_spacy/gpu_uni_tranin90_randomstate10/model-best/')\n",
    "\n",
    "train_data, test_data = train_test_split(list(islice(peykare.sents(), corpus_size)), test_size=0.1, random_state=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73dd99b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "peykare_dict = {}\n",
    "for item in test_data:\n",
    "    peykare_dict[' '.join([w for w, tag in item])] = [w for w, tag in item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a79d711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    if text in peykare_dict:\n",
    "        return Doc(persian_nlp.vocab, peykare_dict[text])\n",
    "    else:\n",
    "        raise ValueError('No tokenization available for input.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea70492",
   "metadata": {},
   "outputs": [],
   "source": [
    "persian_nlp.tokenizer = custom_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "229215a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34474it [25:26, 22.58it/s]              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.96      0.96      0.96     67726\n",
      "      ADJ,EZ       0.95      0.95      0.95     23041\n",
      "         ADP       1.00      1.00      1.00    113035\n",
      "      ADP,EZ       0.98      0.99      0.98     10990\n",
      "         ADV       0.96      0.96      0.96     17844\n",
      "      ADV,EZ       0.97      0.97      0.97      1044\n",
      "       CCONJ       1.00      1.00      1.00     59944\n",
      "    CCONJ,EZ       0.99      0.99      0.99       109\n",
      "         DET       0.98      0.98      0.98     21676\n",
      "      DET,EZ       0.95      0.96      0.95      2337\n",
      "        INTJ       0.92      0.95      0.94        61\n",
      "        NOUN       0.98      0.97      0.98    211663\n",
      "     NOUN,EZ       0.98      0.98      0.98    181162\n",
      "         NUM       0.99      0.99      0.99     26477\n",
      "      NUM,EZ       0.92      0.94      0.93      1874\n",
      "        PRON       0.98      0.99      0.99     25076\n",
      "     PRON,EZ       0.94      0.94      0.94       288\n",
      "       PUNCT       1.00      1.00      1.00     92925\n",
      "       SCONJ       0.99      1.00      0.99     22539\n",
      "        VERB       1.00      1.00      1.00     86510\n",
      "\n",
      "    accuracy                           0.98    966321\n",
      "   macro avg       0.97      0.98      0.97    966321\n",
      "weighted avg       0.98      0.98      0.98    966321\n",
      "\n",
      "Precision                                   : 0.98492\n",
      "Recall                                      : 0.98490\n",
      "F1-Score                                    : 0.98490\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "ys = []\n",
    "not_match = 0\n",
    "\n",
    "for sent in tqdm(test_data, total=int(corpus_size*0.1)):\n",
    "    doc = persian_nlp(' '.join([w for w, tag in sent]))\n",
    "    y = [tag for w, tag in sent]\n",
    "    pred = [w.tag_ for w in doc]\n",
    "    if len(y) == len(pred):\n",
    "        ys += y\n",
    "        preds += pred\n",
    "    else:\n",
    "        not_match +=1\n",
    "\n",
    "\n",
    "print(classification_report(ys, preds))\n",
    "\n",
    "print('Precision                                   : %.5f'%precision_score(ys, preds, average='weighted'))\n",
    "print('Recall                                      : %.5f'%recall_score(ys, preds, average='weighted'))\n",
    "print('F1-Score                                    : %.5f'%f1_score(ys, preds, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f7a0030b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34474it [18:43, 30.68it/s]                                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.96      0.96      0.96     59195\n",
      "      ADJ,EZ       0.95      0.96      0.95     20435\n",
      "         ADP       1.00      1.00      1.00     97477\n",
      "      ADP,EZ       0.98      0.99      0.98      9551\n",
      "         ADV       0.96      0.96      0.96     14963\n",
      "      ADV,EZ       0.97      0.98      0.97       860\n",
      "       CCONJ       1.00      1.00      1.00     50441\n",
      "    CCONJ,EZ       0.99      0.99      0.99        97\n",
      "         DET       0.99      0.98      0.99     18708\n",
      "      DET,EZ       0.95      0.96      0.95      1973\n",
      "        INTJ       0.87      0.94      0.91        36\n",
      "        NOUN       0.98      0.98      0.98    182819\n",
      "     NOUN,EZ       0.98      0.98      0.98    160473\n",
      "         NUM       0.99      0.99      0.99     23916\n",
      "      NUM,EZ       0.92      0.95      0.93      1672\n",
      "        PRON       0.98      0.99      0.99     20160\n",
      "     PRON,EZ       0.94      0.96      0.95       230\n",
      "       PUNCT       1.00      1.00      1.00     79479\n",
      "       SCONJ       0.99      1.00      0.99     18472\n",
      "        VERB       1.00      1.00      1.00     72870\n",
      "\n",
      "    accuracy                           0.99    833827\n",
      "   macro avg       0.97      0.98      0.97    833827\n",
      "weighted avg       0.99      0.99      0.99    833827\n",
      "\n",
      "Precision                                   : 0.98569\n",
      "Recall                                      : 0.98567\n",
      "F1-Score                                    : 0.98568\n"
     ]
    }
   ],
   "source": [
    "persian_nlp = spacy.load('/repo/ebi/myPosTagger/persian_spacy/gpu_uni_tranin90_randomstate10/model-best/')\n",
    "preds = []\n",
    "ys = []\n",
    "not_match = 0\n",
    "\n",
    "for sent in tqdm(test_data, total=int(corpus_size*0.1)):\n",
    "    doc = persian_nlp(' '.join([w for w, tag in sent]))\n",
    "    y = [tag for w, tag in sent]\n",
    "    pred = [w.tag_ for w in doc]\n",
    "    if len(y) == len(pred):\n",
    "        ys += y\n",
    "        preds += pred\n",
    "    else:\n",
    "        not_match +=1\n",
    "\n",
    "\n",
    "print(classification_report(ys, preds))\n",
    "\n",
    "print('Precision                                   : %.5f'%precision_score(ys, preds, average='weighted'))\n",
    "print('Recall                                      : %.5f'%recall_score(ys, preds, average='weighted'))\n",
    "print('F1-Score                                    : %.5f'%f1_score(ys, preds, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e807b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 966321/966321 [00:00<00:00, 1980522.40it/s]\n"
     ]
    }
   ],
   "source": [
    "ys_not_EZ = []\n",
    "pred_not_EZ = []\n",
    "for i in tqdm(range(len(ys))):\n",
    "    ys_not_EZ.append(ys[i].split(',')[0])\n",
    "    pred_not_EZ.append(preds[i].split(',')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b880cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADJ       0.97      0.97      0.97     90763\n",
      "         ADP       1.00      1.00      1.00    123944\n",
      "         ADV       0.96      0.97      0.96     18889\n",
      "       CCONJ       1.00      1.00      1.00     60069\n",
      "         DET       0.98      0.98      0.98     24013\n",
      "        INTJ       0.92      0.95      0.94        61\n",
      "        NOUN       0.99      0.99      0.99    392822\n",
      "         NUM       1.00      1.00      1.00     28359\n",
      "        PRON       0.99      0.99      0.99     25427\n",
      "       PUNCT       1.00      1.00      1.00     92925\n",
      "       SCONJ       0.99      1.00      0.99     22539\n",
      "        VERB       1.00      1.00      1.00     86510\n",
      "\n",
      "    accuracy                           0.99    966321\n",
      "   macro avg       0.98      0.99      0.98    966321\n",
      "weighted avg       0.99      0.99      0.99    966321\n",
      "\n",
      "Precision                                   : 0.99193\n",
      "Recall                                      : 0.99192\n",
      "F1-Score                                    : 0.99192\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ys_not_EZ, pred_not_EZ))\n",
    "\n",
    "print('Precision                                   : %.5f'%precision_score(ys_not_EZ, pred_not_EZ, average='weighted'))\n",
    "print('Recall                                      : %.5f'%recall_score(ys_not_EZ, pred_not_EZ, average='weighted'))\n",
    "print('F1-Score                                    : %.5f'%f1_score(ys_not_EZ, pred_not_EZ, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da785fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 966321/966321 [00:00<00:00, 1959563.73it/s]\n"
     ]
    }
   ],
   "source": [
    "_preds = []\n",
    "_ys = []\n",
    "for i in tqdm(range(len(preds))):\n",
    "    if 'EZ' in preds[i].split(','):\n",
    "        _preds.append('EZ')\n",
    "    else:\n",
    "        _preds.append('-')\n",
    "    \n",
    "    if 'EZ' in ys[i].split(','):\n",
    "        _ys.append('EZ')\n",
    "    else:\n",
    "        _ys.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fd4d20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           -       1.00      0.99      1.00    745476\n",
      "          EZ       0.98      0.99      0.98    220845\n",
      "\n",
      "    accuracy                           0.99    966321\n",
      "   macro avg       0.99      0.99      0.99    966321\n",
      "weighted avg       0.99      0.99      0.99    966321\n",
      "\n",
      "Precision                                   : 0.99255\n",
      "Recall                                      : 0.99253\n",
      "F1-Score                                    : 0.99254\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(_ys, _preds))\n",
    "\n",
    "print('Precision                                   : %.5f'%precision_score(_ys, _preds, average='weighted'))\n",
    "print('Recall                                      : %.5f'%recall_score(_ys, _preds, average='weighted'))\n",
    "print('F1-Score                                    : %.5f'%f1_score(_ys, _preds, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4790fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myVenv",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
